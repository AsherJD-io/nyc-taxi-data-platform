# ğŸš• NYC Taxi Data Platform â€” Data Engineering Zoomcamp

Author

Asher
Data Engineering Zoomcamp Participant (2026)


## Project Structure


``` text
NYC Taxi Data Platform â€” Data Engineering Zoomcamp/
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore
â”œâ”€â”€ Project Overview
â”œâ”€â”€ Architecture Diagram
â”œâ”€â”€ Environment Setup
â”œâ”€â”€ Technologies Used
â”œâ”€â”€ Week-by-Week Breakdown
â”‚   â”œâ”€â”€ Week 1 â€“ Docker, SQL & Terraform
â”‚   â”œâ”€â”€ Week 2 â€“ Workflow Orchestration (Airflow)
â”‚   â”œâ”€â”€ Week 3 â€“ Data Warehousing
â”‚   â”œâ”€â”€ Week 4 â€“ Analytics Engineering
â”‚   â”œâ”€â”€ Week 5 â€“ Data Platforms
â”‚   â”‚   â””â”€â”€ Ingestion with dlt
â”‚   â”œâ”€â”€ Week 6 â€“ Batch
â”‚   â”œâ”€â”€ Week 7 â€“ Streaming
â”‚   â””â”€â”€ Week 8â€“9 â€“ Capstone (Attempt 1 & 2)
â”œâ”€â”€ Key Learnings
â”œâ”€â”€ Known Issues & Tradeoffs
â””â”€â”€ Intializing the Project

```

## PROJECT OVERVIEW

This repository documents my work throughout the DataTalks.Club Data Engineering Zoomcamp, a 9-week, hands-on program focused on building production-grade data pipelines.

Using NYC Taxi trip data as a unifying dataset, the project incrementally evolves from a local, containerized ingestion pipeline into a cloud-based, orchestrated, analytics-ready data platform.

## ARCHITECTURE DIAGRAM

![NYC Taxi Data Platform Architecture](images/architecture/arch_v4_workshops.jpg)

The platform follows a layered architecture where each week adds a new capability without breaking earlier assumptions.

- Early weeks prioritize local reproducibility

- Mid weeks introduce control planes and analytics layers

- Later weeks focus on scale, reliability, and tradeoffs

## ENVIRONMENT SETUP
This project was developed using a local-first, reproducible setup.

### Local Environment

- OS: Windows 11 Pro

- Subsystem: WSL2 (Ubuntu)

- Container Runtime: Docker & Docker Compose

- Language: Python (virtualenv / poetry)

- PostgreSQL & pgAdmin

- IaC: Terraform (installed locally)

### Design Principles

- No local database installations

- All services run in containers

- No credentials or state files committed to Git

- Each week is isolated but composable

## Technologies Used

### Core
- Docker
- PostgreSQL
- Python
- Terraform

### Orchestration & Analytics
- Airflow
- dbt
- BigQuery

### Streaming & Batch
- Kafka
- Spark

### Tooling
- Git
- GitHub

<p align="left">
  <img src="images/technologies/docker.svg" width="40"/>
  <img src="images/technologies/postgresql.svg" width="40"/>
  <img src="images/technologies/python.svg" width="40"/>
  <img src="images/technologies/terraform.svg" width="40"/>
  <img src="images/technologies/airflow.svg" width="40"/>
  <img src="images/technologies/dbt.svg" width="40"/>
  <img src="images/technologies/bigquery.svg" width="40"/>
  <img src="images/technologies/kafka.svg" width="40"/>
</p>

## Week-by-Week Breakdown (Official Zoomcamp Structure)

### Week 1 â€” Docker, SQL & Terraform
- Dockerized PostgreSQL and pgAdmin
- Python-based ingestion pipeline
- SQL exploration on NYC Taxi data
- Terraform fundamentals (init & project structure)

ğŸ“ [`01-docker-terraform/`](./01-docker-terraform)
ğŸ“ [Detailed notes â†’](./01-docker-terraform/README.md)

---

### Week 2 â€” Workflow Orchestration (Airflow)
- DAG authoring and scheduling
- Retries, backfills, and parameterization
- Pipeline orchestration patterns

ğŸ“ `02-workflow-orchestration/`

---

### Week 3 â€” Data Warehousing
- Analytical schema design
- Partitioning strategies
- Warehouse performance considerations

ğŸ“ `03-data-warehouse/`

---

### Week 4 â€” Analytics Engineering
- dbt models and transformations
- Tests and documentation
- Metrics layer design

ğŸ“ `04-analytics-engineering/`

---

### Week 5 â€” Data Platforms
- Ingestion with `dlt`
- Declarative ingestion
- Schema evolution and platform abstractions

ğŸ“ `05-data-platforms/`

---

### Week 6 â€” Batch Processing
- Large-scale batch processing
- Backfills and reruns
- Performance tradeoffs

ğŸ“ `06-batch/`

---

### Week 7 â€” Streaming
- Kafka fundamentals
- Producers and consumers
- Real-time vs batch comparisons

ğŸ“ `07-streaming/`

---

### Week 8â€“9 â€” Capstone (Attempt 1 & 2)
- End-to-end system design
- Architecture iteration
- Lessons learned

ğŸ“ `08-09-capstone/`


## Key Learnings

- Local reproducibility is foundational

- Orchestration is a control plane, not a scheduler

- Analytics engineering bridges data and decision-making

- Production readiness starts early

- Tradeoffs matter more than tools


## Known Issues & Tradeoffs

- Local Docker environments do not reflect cloud scale

- CSV ingestion is instructional, not production-optimal

- Some datasets are sampled to manage resource usage

- All tradeoffs are explicitly documented in weekly READMEs.


## Initializing the Project

```bash
git clone https://github.com/AsherJD-io/nyc-taxi-data-platform.git
docker compose up -d
docker compose run ingestion
```

### Then open pgAdmin:

- URL: http://localhost:8085

- Host: pgdatabase

- Database: ny_taxi
